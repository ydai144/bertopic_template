{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4286c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dimension reduction\n",
    "from umap import UMAP\n",
    "\n",
    "# Clustering\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# Count vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sentence transformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import openai\n",
    "\n",
    "# Topic model\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='iframe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a42f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds model from steps 1 to 5\n",
    "\n",
    "def build_base_model(n_neighbors=15, n_components=5, min_clust_size=10, random_seed=100):\n",
    "    # Step 1 - Extract embeddings\n",
    "    embedding_model = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\") # customizable\n",
    "\n",
    "    # Step 2 - Reduce dimensionality\n",
    "    umap_model = UMAP(n_neighbors=n_neighbors, \\\n",
    "                      n_components=n_components, \\\n",
    "                      min_dist=0.0, \\\n",
    "                      metric='cosine', \\\n",
    "                      random_state=random_seed)\n",
    "\n",
    "    # Step 3 - Cluster reduced embeddings\n",
    "    hdbscan_model = HDBSCAN(min_cluster_size=min_clust_size, \\\n",
    "                            metric='euclidean', \\\n",
    "                            cluster_selection_method='eom', \\\n",
    "                            prediction_data=True)\n",
    "\n",
    "    # Step 4 - Tokenize topics\n",
    "    vectorizer_model = CountVectorizer(stop_words=\"english\", ngram_range=(1,3), min_df=3)\n",
    "\n",
    "    # Step 5 - Create topic representation\n",
    "    ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True) \n",
    "    \n",
    "    return {'embedding': embedding_model, \\\n",
    "            'umap': umap_model, \\\n",
    "            'hdbscan': hdbscan_model, \\\n",
    "            'vectorizer': vectorizer_model, \\\n",
    "            'ctfidf': ctfidf_model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0de54-6ff2-42e1-bdad-245847a96e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds MaximalMarginalRelevance as step 6 to the base model\n",
    "\n",
    "def build_model_mmr(n_neighbors=15, n_components=5, min_clust_size=10, random_seed=100):\n",
    "    base_model_dict = build_base_model(n_neighbors, n_components, min_clust_size, random_seed)\n",
    "    \n",
    "    representation_model = MaximalMarginalRelevance(diversity=0.5)\n",
    "    \n",
    "    # All steps together\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=base_model_dict['embedding'],           # Step 1 - Extract embeddings\n",
    "        umap_model=base_model_dict['umap'],                     # Step 2 - Reduce dimensionality\n",
    "        hdbscan_model=base_model_dict['hdbscan'],               # Step 3 - Cluster reduced embeddings\n",
    "        vectorizer_model=base_model_dict['vectorizer'],         # Step 4 - Tokenize topics\n",
    "        ctfidf_model=base_model_dict['ctfidf'],                 # Step 5 - Extract topic words\n",
    "        representation_model=representation_model,              # Step 6 - (Optional) Fine-tune topic represenations\n",
    "        calculate_probabilities=True\n",
    "    )\n",
    "    return topic_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and run BERTopic model to identify topic representations\n",
    "\n",
    "random_seed = 105\n",
    "n_neighbors = 15\n",
    "n_components = 5\n",
    "min_clust_size = 10\n",
    "topic_model_mmr = build_model_mmr(n_neighbors, n_components, min_clust_size, random_seed=random_seed)\n",
    "\n",
    "# Run BERTopic model\n",
    "topics, probs = topic_model_mmr.fit_transform('<list of documents>')\n",
    "\n",
    "# Get the list of topics\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(topic_model_mmr.get_topic_info())\n",
    "display(topic_model_mmr.visualize_barchart(top_n_topics=100, n_words=15, height=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc4a9b-36e5-4bcc-b117-c28a3fe444f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo-16k\"): \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "openai.organization = \"<ORGANIZATION KEY\"\n",
    "openai.api_key = '<API KEY>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa35534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT to summarize topics\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "delay_in_seconds = 30\n",
    "\n",
    "summarization_prompt = \"\"\"\n",
    "I have a topic that is described by the following keywords: [KEYWORDS]\n",
    "\n",
    "In this topic, the following documents separated by triple tick marks are a small but representative subset of all documents in the topic:\n",
    "[DOCUMENTS]\n",
    "\n",
    "Based on the information above, please give a description of this topic in a JSON object in the following format:\n",
    "{\"topic\": <descriptive topic label with at least 5 words>,\n",
    "\"description\": <description, specifically with regards to attitude toward nephrology>\n",
    "}\n",
    "\n",
    "Reply with only the answer in JSON form or as a JSON-parsable string.\n",
    "\"\"\"\n",
    "\n",
    "chatgpt_responses = []\n",
    "df_topics = topic_model_mmr.get_topic_info()\n",
    "\n",
    "for t in df_topics['Topic']:\n",
    "    rep_docs = topic_model_mmr.get_representative_docs(topic=t)\n",
    "    topic_rep = topic_model_mmr.get_topic(topic=t)\n",
    "    top_words = [pair[0] for pair in topic_rep]\n",
    "\n",
    "    topic_prompt = summarization_prompt.replace('[DOCUMENTS]', '\\n ``` '.join(rep_docs))\n",
    "    topic_prompt = topic_prompt.replace('[KEYWORDS]', ', '.join(top_words))\n",
    "    \n",
    "    response = get_completion(topic_prompt)\n",
    "    print('\\n', t)\n",
    "\n",
    "    response_json = json.loads(response)\n",
    "    response_json['topic_index'] = t\n",
    "    print(response_json)\n",
    "    \n",
    "    chatgpt_responses.append(response_json)\n",
    "    \n",
    "    time.sleep(delay_in_seconds)\n",
    "\n",
    "    \n",
    "df_chatgpt = pd.DataFrame(chatgpt_responses) # contains topic summaries generated by ChatGPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbae814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed documents in 2D space for visualization\n",
    "\n",
    "embedding_model = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\")\n",
    "\n",
    "embeddings = embedding_model.encode(df['message'], show_progress_bar=True)\n",
    "\n",
    "topic_model_mmr.visualize_documents(df['message'], embeddings=embeddings, custom_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9449ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view topics in hierarchical tree\n",
    "\n",
    "hierarchical_topics = topic_model.hierarchical_topics(df['message'])\n",
    "tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "print(tree)\n",
    "\n",
    "# topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics, custom_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60efb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize term rank decrease\n",
    "topic_model.visualize_term_rank(custom_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize intertopic distance\n",
    "topic_model_mmr.visualize_topics(custom_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity using heatmap\n",
    "topic_model_mmr.visualize_heatmap(custom_labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf39_2023] *",
   "language": "python",
   "name": "conda-env-tf39_2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
